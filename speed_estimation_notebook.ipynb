{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone the Github Repo & Install all the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kardSIM/Vehicle_Speed_Estimation.git\n",
    "%cd Vehicle_Speed_Estimation\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r yolov9/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p weights\n",
    "!wget -P weights https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p content\n",
    "!wget -P content https://github.com/AarohiSingla/Speed-detection-of-vehicles/raw/main/highway.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P content https://github.com/AarohiSingla/Speed-detection-of-vehicles/raw/main/highway_mini.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# play input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "def play_video(filename):\n",
    "  html = ''\n",
    "  video = open(filename,'rb').read()\n",
    "  src = 'data:video/mp4;base64,' + b64encode(video).decode()\n",
    "  html += fr'<video width=900 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src\n",
    "  return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls\n",
    "\n",
    "!ffmpeg -i content/highway_mini.mp4 -vcodec libx264 content/highway_minic.mp4\n",
    "\n",
    "play_video(\"content/highway_minic.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "current_directory = Path().resolve()\n",
    "yolov9_path = current_directory / \"yolov9\"\n",
    "utils_path = yolov9_path / \"utils\"\n",
    "sys.path.insert(0, str(utils_path))  \n",
    "sys.path.insert(0, str(yolov9_path))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import colorsys\n",
    "import numpy as np\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from yolov9.models.common import DetectMultiBackend, AutoShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_VIDEO_PATH = \"content/highway_minic.mp4\"\n",
    "OUTPUT_VIDEO_PATH = \"content/speed.mp4\"\n",
    "BLUR_ID = None\n",
    "CONF = 0.6\n",
    "CLASS_ID = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_WIDTH=30\n",
    "FRAME_HEIGHT=100\n",
    "\n",
    "\n",
    "SOURCE_POLYGONE = np.array([[18, 550], [1852, 608],[1335, 370], [534, 343]], dtype=np.float32)\n",
    "BIRD_EYE_VIEW = np.array([[0, 0], [FRAME_WIDTH, 0], [FRAME_WIDTH, FRAME_HEIGHT],[0, FRAME_HEIGHT]], dtype=np.float32)\n",
    "\n",
    "M = cv2.getPerspectiveTransform(SOURCE_POLYGONE, BIRD_EYE_VIEW)\n",
    "\n",
    "\n",
    "#Transform a polygon into a bird's-eye view using perspective transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames():\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        yield frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_speed(distance, fps):\n",
    "    return (distance *fps)*3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(p1, p2):\n",
    "    return np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_corner_rect(img, bbox, line_length=30, line_thickness=5, rect_thickness=1,\n",
    "                     rect_color=(255, 0, 255), line_color=(0, 255, 0)):\n",
    "    x, y, w, h = bbox\n",
    "    x1, y1 = x + w, y + h\n",
    "\n",
    "    if rect_thickness != 0:\n",
    "        cv2.rectangle(img, bbox, rect_color, rect_thickness)\n",
    "\n",
    "    # Top Left  x, y\n",
    "    cv2.line(img, (x, y), (x + line_length, y), line_color, line_thickness)\n",
    "    cv2.line(img, (x, y), (x, y + line_length), line_color, line_thickness)\n",
    "\n",
    "    # Top Right  x1, y\n",
    "    cv2.line(img, (x1, y), (x1 - line_length, y), line_color, line_thickness)\n",
    "    cv2.line(img, (x1, y), (x1, y + line_length), line_color, line_thickness)\n",
    "\n",
    "    # Bottom Left  x, y1\n",
    "    cv2.line(img, (x, y1), (x + line_length, y1), line_color, line_thickness)\n",
    "    cv2.line(img, (x, y1), (x, y1 - line_length), line_color, line_thickness)\n",
    "\n",
    "    # Bottom Right  x1, y1\n",
    "    cv2.line(img, (x1, y1), (x1 - line_length, y1), line_color, line_thickness)\n",
    "    cv2.line(img, (x1, y1), (x1, y1 - line_length), line_color, line_thickness)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the video capture\n",
    "cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
    "frame_generator = read_frames()\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "#Create mask to filter detections\n",
    "pts = SOURCE_POLYGONE.astype(np.int32) \n",
    "pts = pts.reshape((-1, 1, 2))\n",
    "polygon_mask = np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
    "cv2.fillPoly(polygon_mask, [pts], 255)\n",
    "\n",
    "# Initialize the video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "writer = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Initialize the DeepSort tracker\n",
    "tracker = DeepSort(max_age=50)\n",
    "# select device (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load YOLO model\n",
    "model = DetectMultiBackend(weights='weights/yolov9-e.pt',device=device, fuse=True)\n",
    "model = AutoShape(model)\n",
    "# Load the COCO class labels\n",
    "classes_path = \"configs/coco.names\"\n",
    "with open(classes_path, \"r\") as f:\n",
    "    class_names = f.read().strip().split(\"\\n\")\n",
    "# Create a list of random colors to represent each class\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(class_names), 3)) \n",
    "# FPS calculation variables\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "prev_positions={}\n",
    "speed_accumulator={}\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        frame = next(frame_generator)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    # Run model on each frame\n",
    "    results = model(frame)\n",
    "    detect = []\n",
    "    for det in results.pred[0]:\n",
    "        label, confidence, bbox = det[5], det[4], det[:4]\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        class_id = int(label)\n",
    "        \n",
    "        # Filter out weak detections by confidence threshold and class_id\n",
    "        if CLASS_ID is None:\n",
    "            if confidence < CONF:\n",
    "                continue\n",
    "        else:\n",
    "            if class_id != CLASS_ID or confidence < CONF:\n",
    "                continue            \n",
    "        \n",
    "        if polygon_mask[(y1 + y2) // 2, (x1 + x2) // 2] == 255:\n",
    "            detect.append([[x1, y1, x2 - x1, y2 - y1], confidence, int(label)])   \n",
    "                   \n",
    "    tracks = tracker.update_tracks(detect, frame=frame)\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id    \n",
    "        ltrb = track.to_ltrb()\n",
    "        class_id = track.get_det_class()\n",
    "        x1, y1, x2, y2 = map(int, ltrb)\n",
    "        if polygon_mask[(y1+y2)//2,(x1+x2)//2] == 0:\n",
    "            tracks.remove(track)\n",
    "        color = colors[class_id]\n",
    "        B, G, R = map(int, color)\n",
    "        text = f\"{track_id} - {class_names[class_id]}\"\n",
    "        center_pt = np.array([[(x1+x2)//2, (y1+y2)//2]], dtype=np.float32)\n",
    "        transformed_pt = cv2.perspectiveTransform(center_pt[None, :, :], M)\n",
    "\n",
    "        #Process distance and speed calculations by using previous predictions\n",
    "        if track_id in prev_positions:\n",
    "            prev_position = prev_positions[track_id]\n",
    "            distance = calculate_distance(prev_position, transformed_pt[0][0])\n",
    "            speed = calculate_speed(distance, fps)\n",
    "            if track_id in speed_accumulator:\n",
    "                speed_accumulator[track_id].append(speed)\n",
    "                if len(speed_accumulator[track_id]) > 100:\n",
    "                    speed_accumulator[track_id].pop(0)\n",
    "            else:\n",
    "                speed_accumulator[track_id] = []\n",
    "                speed_accumulator[track_id].append(speed)\n",
    "        prev_positions[track_id] = transformed_pt[0][0]\n",
    "\n",
    "        # Draw bounding box and text\n",
    "        frame = draw_corner_rect(frame, (x1, y1, x2 - x1, y2 - y1), line_length=15, line_thickness=3, rect_thickness=1, rect_color=(B, G, R), line_color=(R, G, B))\n",
    "        #cv2.rectangle(frame, (x1, y1), (x2, y2), (B, G, R), 2)\n",
    "        cv2.rectangle(frame, (x1 - 1, y1 - 20), (x1 + len(text) * 10, y1), (B, G, R), -1)\n",
    "        cv2.putText(frame, text, (x1 + 5, y1 - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        cv2.polylines(frame, [pts], isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "        if track_id in speed_accumulator :\n",
    "            avg_speed = sum(speed_accumulator[track_id]) / len(speed_accumulator[track_id])\n",
    "            cv2.rectangle(frame, (x1 - 1, y1-40 ), (x1 + len(f\"Speed: {avg_speed:.0f} km/h\") * 10, y1-20), (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"Speed: {avg_speed:.0f} km/h\", (x1, y1 - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        # Apply Gaussian Blur\n",
    "        if BLUR_ID is not None and class_id == BLUR_ID:\n",
    "            if 0 <= x1 < x2 <= frame.shape[1] and 0 <= y1 < y2 <= frame.shape[0]:\n",
    "                frame[y1:y2, x1:x2] = cv2.GaussianBlur(frame[y1:y2, x1:x2], (99, 99), 3)\n",
    "    writer.write(frame)\n",
    "    frame_count += 1\n",
    "    if frame_count % 10 == 0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        fps_calc = frame_count / elapsed_time\n",
    "        print(f\"FPS: {fps_calc:.2f}\")\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release video capture and writer\n",
    "cap.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# play output video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i content/speed.mp4 -vcodec libx264 content/speeds.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(\"content/speeds.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
